{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b319f75",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5737192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: myfm in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (0.3.5)\r\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from myfm) (1.3.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from myfm) (4.3.0)\r\n",
      "Requirement already satisfied: tqdm>=4 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from myfm) (4.62.3)\r\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from myfm) (1.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from myfm) (1.22.3)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from pandas>=1.0.0->myfm) (2022.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from pandas>=1.0.0->myfm) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/samyakjain/miniforge3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->myfm) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "#Install package to apply Bayesian Factorization Machine\n",
    "!pip install myfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83dc77",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbe7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To apply Factorization Machines\n",
    "import myfm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# To do train-test split for evaluation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14d436",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3563ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract users, movies and ratings from raw data\n",
    "def extract_users_items_predictions(data_pd):\n",
    "    users, movies = \\\n",
    "        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
    "    predictions = data_pd.Prediction.values\n",
    "    return users, movies, predictions\n",
    "\n",
    "#Load raw data\n",
    "data_pd = pd.read_csv('data/data_train.csv')\n",
    "\n",
    "#Do Train-Test Split\n",
    "train, val = train_test_split(data_pd, test_size=0.1,random_state=42)\n",
    "\n",
    "#Extract users, movies and ratings from raw data\n",
    "total_users, total_movies, total_pred = extract_users_items_predictions(data_pd)\n",
    "train_users, train_movies, train_pred = extract_users_items_predictions(train)\n",
    "val_users, val_movies, val_pred = extract_users_items_predictions(val)\n",
    "\n",
    "#Store total data\n",
    "ratings_dict_total = {'userID': total_users,'movieID': total_movies,'rating': total_pred}\n",
    "df_total = pd.DataFrame(ratings_dict_total)\n",
    "\n",
    "#Store train data\n",
    "ratings_dict_train = {'userID': train_users,'movieID': train_movies,'rating': train_pred}\n",
    "df_train = pd.DataFrame(ratings_dict_train)\n",
    "\n",
    "#Store validation data\n",
    "ratings_dict_test = {'userID': val_users,'movieID': val_movies,'rating': val_pred}\n",
    "df_test = pd.DataFrame(ratings_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c72d4f",
   "metadata": {},
   "source": [
    "## Apply Bayesian Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c593ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''code adapted from https://github.com/tohtsky/myFM'''\n",
    "def factorization_machine(df_train, df_test=pd.Series([]), rank=12, grouping=None, n_iter=500, samples=495):\n",
    "    explanation_columns = [\"userID\", \"movieID\"]\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    X_train = ohe.fit_transform(df_train[explanation_columns])\n",
    "    y_train = df_train.rating.values\n",
    "    fm = myfm.MyFMRegressor(rank=rank, random_seed=1234)\n",
    "\n",
    "    if grouping:\n",
    "        # specify how columns of X_train are grouped\n",
    "        group_shapes = [len(category) for category in ohe.categories_]\n",
    "        assert sum(group_shapes) == X_train.shape[1]\n",
    "    else:\n",
    "        group_shapes = None\n",
    "\n",
    "    fm.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        group_shapes=group_shapes,\n",
    "        n_iter=n_iter,\n",
    "        n_kept_samples=samples,\n",
    "    )\n",
    "    prediction = None\n",
    "    if not df_test.empty:\n",
    "        X_test = ohe.transform(df_test[explanation_columns])\n",
    "        y_test = df_test.rating.values\n",
    "        prediction = fm.predict(X_test)\n",
    "    return fm,prediction,ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7e813",
   "metadata": {},
   "source": [
    "## Evaluation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc61da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.78 : 100%|████████████████| 100/100 [00:18<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786862959741647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.78 : 100%|████████████████| 200/200 [00:37<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9780474944790564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.79 : 100%|████████████████| 300/300 [00:56<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978031974607306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.80 : 100%|████████████████| 400/400 [01:15<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9780192776453689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.84 : 100%|████████████████| 500/500 [01:34<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9780132791681007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.77 : 100%|████████████████| 100/100 [00:23<00:00,  4.28it/s]\n",
      "alpha = 1.13 w0 = 3.79 : 100%|████████████████| 200/200 [00:46<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777867974646192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.81 : 100%|████████████████| 300/300 [01:10<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776467145136033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.83 : 100%|████████████████| 400/400 [01:33<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9776108507449198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.84 : 100%|████████████████| 500/500 [01:56<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775757919279762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.15 w0 = 3.78 : 100%|████████████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "alpha = 1.15 w0 = 3.79 : 100%|████████████████| 200/200 [00:55<00:00,  3.62it/s]\n",
      "alpha = 1.15 w0 = 3.81 : 100%|████████████████| 300/300 [01:22<00:00,  3.64it/s]\n",
      "alpha = 1.15 w0 = 3.84 : 100%|████████████████| 400/400 [01:55<00:00,  3.45it/s]\n",
      "alpha = 1.15 w0 = 3.86 : 100%|████████████████| 500/500 [02:14<00:00,  3.73it/s]\n",
      "alpha = 1.16 w0 = 3.77 : 100%|████████████████| 100/100 [00:31<00:00,  3.21it/s]\n",
      "alpha = 1.17 w0 = 3.81 : 100%|████████████████| 200/200 [01:03<00:00,  3.16it/s]\n",
      "alpha = 1.16 w0 = 3.84 : 100%|████████████████| 300/300 [01:34<00:00,  3.16it/s]\n",
      "alpha = 1.16 w0 = 3.88 : 100%|████████████████| 400/400 [02:10<00:00,  3.07it/s]\n",
      "alpha = 1.16 w0 = 3.90 : 100%|████████████████| 500/500 [02:43<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Return root mean square error metric\n",
    "def RMSE(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    return np.sqrt(np.average((x - y) ** 2))\n",
    "\n",
    "# Function to do parameter tuning\n",
    "def validation(df_train,df_test,val_predictions):\n",
    "  \n",
    "    rank = [8,10,12,14]\n",
    "    n_iter = [100,200,300,400,500]\n",
    "    n_samples = [95,195,295,395,495]\n",
    "\n",
    "    best_rmse = 1\n",
    "    best_r = 0\n",
    "    best_n = 0\n",
    "    best_s = 0\n",
    "\n",
    "    for r in rank:\n",
    "        for i in range(len(n_iter)):\n",
    "            fm,test_predictions,ohe = factorization_machine(df_train, df_test, r,True,n_iter[i],n_samples[i])\n",
    "            rmse = RMSE(val_predictions,test_predictions)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_r = r\n",
    "                best_n = n_iter[i]\n",
    "                best_s = n_samples[i]\n",
    "                print(best_rmse)\n",
    "                \n",
    "    return best_rmse,best_r,best_n,best_s\n",
    "\n",
    "best_rmse,best_r,best_n,best_s = validation(df_train,df_test,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50af65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE using model is 0.9775757919279762\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation RMSE using model is \" + str(best_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac285dc6",
   "metadata": {},
   "source": [
    "# Train the model on Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb901a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/73/926mvg9d3h35fm6dg1nhzc780000gn/T/ipykernel_36039/2967863098.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  fm,test_predictions,ohe = factorization_machine(df_total,pd.Series([]),best_r,True,best_n,best_s)\n",
      "alpha = 1.13 w0 = 3.84 : 100%|████████████████| 500/500 [01:20<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "fm,test_predictions,ohe = factorization_machine(df_total,pd.Series([]),best_r,True,best_n,best_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68a8d2",
   "metadata": {},
   "source": [
    "## Generate predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8db3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Submission File\n",
    "sub_pd = pd.read_csv('data/sampleSubmission.csv')\n",
    "sub_users, sub_movies, sub_pred = extract_users_items_predictions(sub_pd)\n",
    "sub_test_ratings_dict = {'userID': sub_users,'movieID': sub_movies,'rating': sub_pred}\n",
    "sub_df = pd.DataFrame(sub_test_ratings_dict)\n",
    "\n",
    "#Generate Predictions and create submission csv    \n",
    "X_test = ohe.transform(sub_df[[\"userID\", \"movieID\"]])\n",
    "predictions = fm.predict(X_test)\n",
    "sub_pd['Prediction'] = predictions\n",
    "sub_pd.set_index(\"Id\", inplace = True)\n",
    "sub_pd.to_csv(\"submission_bayesian_factorization_machine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cf8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
