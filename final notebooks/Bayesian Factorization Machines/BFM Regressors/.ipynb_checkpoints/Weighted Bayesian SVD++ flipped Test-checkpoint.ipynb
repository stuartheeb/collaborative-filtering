{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b319f75",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5737192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install packages to apply SVD and Bayesian Factorization Machine\n",
    "!pip install surprise\n",
    "\n",
    "!pip install myfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83dc77",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbe7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To apply SVD\n",
    "import surprise\n",
    "\n",
    "# To apply Factorization Machines\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "from myfm.utils.encoders import(DataFrameEncoder,MultipleValuesToSparseEncoder,CategoryValueToSparseEncoder)\n",
    "\n",
    "# To do train-test split for evaluation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14d436",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3563ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract users, movies and ratings from raw data\n",
    "def extract_users_items_predictions(data_pd):\n",
    "    users, movies = \\\n",
    "        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
    "    predictions = data_pd.Prediction.values\n",
    "    return users, movies, predictions\n",
    "\n",
    "#Load raw data\n",
    "data_pd = pd.read_csv('../../../data/data_train.csv')\n",
    "\n",
    "#Do Train-Test Split\n",
    "train, val = train_test_split(data_pd, test_size=0.1,random_state=42)\n",
    "\n",
    "#Extract users, movies and ratings from raw data\n",
    "total_users, total_movies, total_pred = extract_users_items_predictions(data_pd)\n",
    "train_users, train_movies, train_pred = extract_users_items_predictions(train)\n",
    "val_users, val_movies, val_pred = extract_users_items_predictions(val)\n",
    "\n",
    "#Store total data\n",
    "ratings_dict_total = {'userID': total_users,'movieID': total_movies,'rating': total_pred}\n",
    "df_total = pd.DataFrame(ratings_dict_total)\n",
    "\n",
    "#Store train data\n",
    "ratings_dict_train = {'userID': train_users,'movieID': train_movies,'rating': train_pred}\n",
    "df_train = pd.DataFrame(ratings_dict_train)\n",
    "\n",
    "#Store validation data\n",
    "ratings_dict_test = {'userID': val_users,'movieID': val_movies,'rating': val_pred}\n",
    "df_test = pd.DataFrame(ratings_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bad323",
   "metadata": {},
   "source": [
    "## Get implicit user/movie Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d81506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code adapted from https://github.com/tohtsky/myFM/blob/main/examples/ml-100k-extended.ipynb'''\n",
    "\n",
    "#Utility function to convert list to str\n",
    "def string_agg(int_list) -> str:\n",
    "    return ','.join([str(y) for y in int_list])\n",
    "\n",
    "def aggr(int_list):\n",
    "    return [y for y in int_list]\n",
    "\n",
    "#Get & Store Implicit Features\n",
    "user_f = pd.DataFrame(np.arange(10000),columns=['userID'])\n",
    "user_f['implicit_features'] = df_train.groupby('userID').movieID.agg(string_agg).reindex(user_f.index).fillna('')\n",
    "user_f['rating_features'] = df_train.groupby('userID').rating.agg(aggr).reindex(user_f.index).fillna('')\n",
    "user_f['user_metadata'] = user_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "movie_f = pd.DataFrame(np.arange(1000),columns=['movieID'])\n",
    "movie_f['implicit_features'] = df_train.groupby('movieID').userID.agg(string_agg).reindex(movie_f.index).fillna('')\n",
    "movie_f['rating_features'] = df_train.groupby('movieID').rating.agg(aggr).reindex(movie_f.index).fillna('')\n",
    "movie_f['movie_metadata'] = movie_f[['implicit_features', 'rating_features']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f5430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>implicit_features</th>\n",
       "      <th>rating_features</th>\n",
       "      <th>user_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60,83,473,438,471,309,604,641,621,545,642,391,...</td>\n",
       "      <td>[5, 4, 2, 4, 4, 4, 5, 5, 4, 5, 5, 5, 5, 2, 2, ...</td>\n",
       "      <td>{'implicit_features': '60,83,473,438,471,309,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>396,458,821,212,337,631,696,219,69,257,667,999...</td>\n",
       "      <td>[3, 4, 3, 5, 3, 5, 5, 3, 2, 5, 4, 3, 4, 3, 5, ...</td>\n",
       "      <td>{'implicit_features': '396,458,821,212,337,631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>61,330,142,45,924,229,270,985,476,570,417,68,9...</td>\n",
       "      <td>[3, 3, 4, 5, 4, 3, 4, 2, 3, 2, 4, 5, 2, 3, 2, ...</td>\n",
       "      <td>{'implicit_features': '61,330,142,45,924,229,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>89,755,190,470,59,642,662,45,301,256,546,234,6...</td>\n",
       "      <td>[5, 5, 5, 1, 5, 4, 3, 3, 5, 4, 4, 4, 2, 3, 5, ...</td>\n",
       "      <td>{'implicit_features': '89,755,190,470,59,642,6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>610,559,656,643,498,631,71,5,100,284,99,1,970,...</td>\n",
       "      <td>[5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 2, 2, 4, 3, 2, ...</td>\n",
       "      <td>{'implicit_features': '610,559,656,643,498,631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>210,598,22,842,659,596,214,501,675,770,552,45,...</td>\n",
       "      <td>[4, 2, 4, 4, 5, 5, 4, 5, 5, 1, 4, 5, 5, 3, 5, ...</td>\n",
       "      <td>{'implicit_features': '210,598,22,842,659,596,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>999,784,454,973,255,494,7,785,764,652,387,489,...</td>\n",
       "      <td>[4, 3, 1, 5, 5, 3, 5, 3, 4, 5, 1, 4, 3, 5, 5, ...</td>\n",
       "      <td>{'implicit_features': '999,784,454,973,255,494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>410,7,481,425,568,876,121,91,432,70,840,397,31...</td>\n",
       "      <td>[3, 4, 4, 3, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, ...</td>\n",
       "      <td>{'implicit_features': '410,7,481,425,568,876,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>683,769,968,3,533,472,875,854,185,88,317,553,6...</td>\n",
       "      <td>[5, 4, 4, 5, 5, 5, 5, 4, 3, 4, 3, 3, 5, 2, 3, ...</td>\n",
       "      <td>{'implicit_features': '683,769,968,3,533,472,8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>233,397,394,60,575,425,223,295,170,554,396,590...</td>\n",
       "      <td>[5, 5, 4, 4, 3, 5, 4, 5, 5, 3, 3, 3, 5, 4, 5, ...</td>\n",
       "      <td>{'implicit_features': '233,397,394,60,575,425,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID                                  implicit_features  \\\n",
       "0          0  60,83,473,438,471,309,604,641,621,545,642,391,...   \n",
       "1          1  396,458,821,212,337,631,696,219,69,257,667,999...   \n",
       "2          2  61,330,142,45,924,229,270,985,476,570,417,68,9...   \n",
       "3          3  89,755,190,470,59,642,662,45,301,256,546,234,6...   \n",
       "4          4  610,559,656,643,498,631,71,5,100,284,99,1,970,...   \n",
       "...      ...                                                ...   \n",
       "9995    9995  210,598,22,842,659,596,214,501,675,770,552,45,...   \n",
       "9996    9996  999,784,454,973,255,494,7,785,764,652,387,489,...   \n",
       "9997    9997  410,7,481,425,568,876,121,91,432,70,840,397,31...   \n",
       "9998    9998  683,769,968,3,533,472,875,854,185,88,317,553,6...   \n",
       "9999    9999  233,397,394,60,575,425,223,295,170,554,396,590...   \n",
       "\n",
       "                                        rating_features  \\\n",
       "0     [5, 4, 2, 4, 4, 4, 5, 5, 4, 5, 5, 5, 5, 2, 2, ...   \n",
       "1     [3, 4, 3, 5, 3, 5, 5, 3, 2, 5, 4, 3, 4, 3, 5, ...   \n",
       "2     [3, 3, 4, 5, 4, 3, 4, 2, 3, 2, 4, 5, 2, 3, 2, ...   \n",
       "3     [5, 5, 5, 1, 5, 4, 3, 3, 5, 4, 4, 4, 2, 3, 5, ...   \n",
       "4     [5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 2, 2, 4, 3, 2, ...   \n",
       "...                                                 ...   \n",
       "9995  [4, 2, 4, 4, 5, 5, 4, 5, 5, 1, 4, 5, 5, 3, 5, ...   \n",
       "9996  [4, 3, 1, 5, 5, 3, 5, 3, 4, 5, 1, 4, 3, 5, 5, ...   \n",
       "9997  [3, 4, 4, 3, 4, 4, 3, 4, 4, 2, 4, 4, 3, 4, 4, ...   \n",
       "9998  [5, 4, 4, 5, 5, 5, 5, 4, 3, 4, 3, 3, 5, 2, 3, ...   \n",
       "9999  [5, 5, 4, 4, 3, 5, 4, 5, 5, 3, 3, 3, 5, 4, 5, ...   \n",
       "\n",
       "                                          user_metadata  \n",
       "0     {'implicit_features': '60,83,473,438,471,309,6...  \n",
       "1     {'implicit_features': '396,458,821,212,337,631...  \n",
       "2     {'implicit_features': '61,330,142,45,924,229,2...  \n",
       "3     {'implicit_features': '89,755,190,470,59,642,6...  \n",
       "4     {'implicit_features': '610,559,656,643,498,631...  \n",
       "...                                                 ...  \n",
       "9995  {'implicit_features': '210,598,22,842,659,596,...  \n",
       "9996  {'implicit_features': '999,784,454,973,255,494...  \n",
       "9997  {'implicit_features': '410,7,481,425,568,876,1...  \n",
       "9998  {'implicit_features': '683,769,968,3,533,472,8...  \n",
       "9999  {'implicit_features': '233,397,394,60,575,425,...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a974c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020ff52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'implicit_features': '60,83,473,438,471,309,604,641,621,545,642,391,590,205,981,966,9,920,594,595,791,778',\n",
       " 'rating_features': [5,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  3,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_f['user_metadata'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5ec24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bc42151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "\n",
    "class WeightMultipleValuesToSparseEncoder(CategoryValueToSparseEncoder[str]):\n",
    "    \"\"\"The class to N-hot encode a List of items into a sparse matrix representation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        items: Iterable[str],\n",
    "        min_freq: int = 1,\n",
    "        sep: str = \",\",\n",
    "        normalize: bool = True,\n",
    "        handle_unknown: Literal[\"create\", \"ignore\", \"raise\"] = \"create\",\n",
    "    ):\n",
    "        \"\"\"Construct the encoder by providing a list of strings,\n",
    "        each of which is a list of strings concatenated by `sep`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        items : Iterable[str]\n",
    "            Iterable of strings, each of which is a concatenated list of possibly multiple items.\n",
    "        min_freq : int, optional\n",
    "            The minimal frequency for an item to be retained in the known items list, by default 1.\n",
    "        sep: str, optional\n",
    "            Tells how to separate string back into a list. Defaults to `','`.\n",
    "        normalize: bool, optional\n",
    "            If `True`, non-zero entry in the encoded matrix will have `1 / N ** 0.5`,\n",
    "            where `N` is the number of non-zero entries in that row. Defaults to `True`.\n",
    "        handle_unknown: Literal[\"create\", \"ignore\", \"raise\"], optional\n",
    "            How to handle previously unseen values during encoding.\n",
    "            If \"create\", then there is a single category named \"__UNK__\" for unknown values,\n",
    "            ant it is treated as 0th category.\n",
    "            If \"ignore\", such an item will be ignored.\n",
    "            If \"raise\", a `KeyError` is raised.\n",
    "            Defaults to \"create\".\n",
    "        \"\"\"\n",
    "        items_flatten = [\n",
    "            y for x in items for y in set(x['implicit_features'].split(sep)) if y\n",
    "        ]  # ignore empty string.\n",
    "        self.sep = sep\n",
    "        self.normalize = normalize\n",
    "        super().__init__(\n",
    "            items_flatten, min_freq=min_freq, handle_unknown=handle_unknown\n",
    "        )\n",
    "\n",
    "    def to_sparse(self, items: Iterable[str]) -> sps.csr_matrix:\n",
    "        indptr = [0]\n",
    "        indices = []\n",
    "        data = []\n",
    "        n_row = 0\n",
    "        cursor = 0\n",
    "        for row in items:\n",
    "            #print(\"***\")\n",
    "            n_row += 1\n",
    "            items = row['implicit_features'].split(self.sep)\n",
    "            '''for v in items:\n",
    "                print((v,self._get_index(v)))'''\n",
    "            '''indices_local = list(\n",
    "                    {\n",
    "                        index\n",
    "                        for index in [self._get_index(v) for v in items if v]\n",
    "                        if index is not None\n",
    "                    }\n",
    "                \n",
    "            )'''\n",
    "            indices_local = [self._get_index(v) for v in items if v]\n",
    "            \n",
    "           \n",
    "\n",
    "            if not indices_local:\n",
    "                indptr.append(cursor)\n",
    "                continue\n",
    "            n = len(indices_local)\n",
    "            #value = 1.0 / (float(n) ** 0.5) if self.normalize else 1.0\n",
    "            indices.extend(indices_local)\n",
    "            #data.extend([value] * n)\n",
    "            weights = row['rating_features']\n",
    "            total_weights = sum(weights)\n",
    "            values = []\n",
    "            for i in range(n):\n",
    "                values.append(weights[i] / total_weights)\n",
    "            data.extend(values)\n",
    "                \n",
    "            cursor += n\n",
    "            indptr.append(cursor)\n",
    "        return sps.csr_matrix(\n",
    "            (data, indices, indptr),\n",
    "            shape=(n_row, len(self)),\n",
    "        )\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e47d8",
   "metadata": {},
   "source": [
    "# Transform Data in myfm Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b39cee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create User Encoder\n",
    "user_encoder = DataFrameEncoder().add_column(\n",
    "    'userID', CategoryValueToSparseEncoder(user_f.userID)\n",
    "    )\n",
    "\n",
    "user_encoder.add_column(\n",
    "        'user_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(user_f.user_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Movie Encoder\n",
    "movie_encoder = DataFrameEncoder().add_column(\n",
    "    'movieID', CategoryValueToSparseEncoder(movie_f.movieID)\n",
    "    )\n",
    "movie_encoder.add_column(\n",
    "        'movie_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(movie_f.movie_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def augment_user_id(user_ids):\n",
    "    return user_encoder.encode_df(\n",
    "        user_f.reindex(user_ids).reset_index()\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    return movie_encoder.encode_df(\n",
    "        movie_f.reindex(movie_ids).reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Train/Test Blocks\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks),(df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7e813",
   "metadata": {},
   "source": [
    "## Evaluation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fc61da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.15 w0 = 3.85 : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [04:12<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750857112723097\n"
     ]
    }
   ],
   "source": [
    "# Return root mean square error metric\n",
    "def RMSE(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    return np.sqrt(np.average((x - y) ** 2))\n",
    "\n",
    "# Function to do parameter tuning\n",
    "def validation(user_encoder,movie_encoder,df_train,train_blocks,test_blocks,val_predictions):\n",
    "    group_shapes = user_encoder.encoder_shapes + movie_encoder.encoder_shapes\n",
    "\n",
    "    rank = [8,10,12,14]\n",
    "    n_iter = [100,200,300,400,500]\n",
    "    n_samples = [495]\n",
    "\n",
    "    best_rmse = 1\n",
    "    best_r = 0\n",
    "    best_n = 0\n",
    "    best_s = 0\n",
    "\n",
    "    for r in rank:\n",
    "        for i in range(len(n_iter)):\n",
    "            fm = myfm.MyFMRegressor(rank=r,random_seed=1234)\n",
    "            fm.fit(None, df_train.rating.values, X_rel=train_blocks, \n",
    "                   group_shapes=group_shapes,n_iter=n_iter[i], n_kept_samples=n_samples[i])\n",
    "            test_predictions = fm.predict(None, test_blocks)\n",
    "            rmse = RMSE(val_predictions,test_predictions)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_r = r\n",
    "                best_n = n_iter[i]\n",
    "                best_s = n_samples[i]\n",
    "                print(best_rmse)\n",
    "                \n",
    "    return best_rmse,best_r,best_n,best_s\n",
    "\n",
    "best_rmse,best_r,best_n,best_s = validation(user_encoder,movie_encoder,df_train,train_blocks,test_blocks,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50af65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE using model is 0.9731564794960696\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation RMSE using model is \" + str(best_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac285dc6",
   "metadata": {},
   "source": [
    "# Generate Features & Train the model on Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb901a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.78 : 100%|████████████████| 300/300 [03:02<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<myfm.gibbs.MyFMGibbsRegressor at 0x1595de400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get & Store Implicit Features on total data\n",
    "user_f = pd.DataFrame(np.arange(10000),columns=['userID'])\n",
    "user_f['implicit_features'] = df_total.groupby('userID').movieID.agg(string_agg).reindex(user_f.index).fillna('')\n",
    "user_f['rating_features'] = df_total.groupby('userID').rating.agg(aggr).reindex(user_f.index).fillna('')\n",
    "user_f['user_metadata'] = user_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "movie_f = pd.DataFrame(np.arange(1000),columns=['movieID'])\n",
    "movie_f['implicit_features'] = df_total.groupby('movieID').userID.agg(string_agg).reindex(movie_f.index).fillna('')\n",
    "movie_f['rating_features'] = df_total.groupby('movieID').rating.agg(aggr).reindex(movie_f.index).fillna('')\n",
    "movie_f['movie_metadata'] = movie_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "#Create User Encoder for total data\n",
    "user_encoder = DataFrameEncoder().add_column(\n",
    "    'userID', CategoryValueToSparseEncoder(user_f.userID)\n",
    "    )\n",
    "\n",
    "user_encoder.add_column(\n",
    "        'user_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(user_f.user_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Movie Encoder\n",
    "movie_encoder = DataFrameEncoder().add_column(\n",
    "    'movieID', CategoryValueToSparseEncoder(movie_f.movieID)\n",
    "    )\n",
    "movie_encoder.add_column(\n",
    "        'movie_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(movie_f.movie_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def augment_user_id(user_ids):\n",
    "    return user_encoder.encode_df(\n",
    "        user_f.reindex(user_ids).reset_index()\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    return movie_encoder.encode_df(\n",
    "        movie_f.reindex(movie_ids).reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "#Generate Train Blocks on total data\n",
    "group_shapes = user_encoder.encoder_shapes + movie_encoder.encoder_shapes\n",
    "\n",
    "total_train_blocks = []\n",
    "for source, target in [(df_total, total_train_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )\n",
    "\n",
    "\n",
    "#Train the model\n",
    "fm = myfm.MyFMRegressor(rank=best_r,random_seed=1234)\n",
    "fm.fit(None, df_total.rating.values, X_rel=total_train_blocks,\n",
    "    group_shapes=group_shapes,\n",
    "    n_iter=best_n, n_kept_samples=best_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68a8d2",
   "metadata": {},
   "source": [
    "## Generate predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8db3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Submission File\n",
    "sub_pd = pd.read_csv('../data/sampleSubmission.csv')\n",
    "sub_users, sub_movies, sub_pred = extract_users_items_predictions(sub_pd)\n",
    "sub_test_ratings_dict = {'userID': sub_users,'movieID': sub_movies,'rating': sub_pred}\n",
    "sub_df = pd.DataFrame(sub_test_ratings_dict)\n",
    "\n",
    "#Generate Submission Test Blocks\n",
    "sub_test_blocks = []\n",
    "for source, target in [(sub_df, sub_test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )\n",
    "\n",
    "#Generate Predictions and create submission csv    \n",
    "predictions = fm.predict(None, sub_test_blocks)\n",
    "sub_pd['Prediction'] = predictions\n",
    "sub_pd.set_index(\"Id\", inplace = True)\n",
    "sub_pd.to_csv(\"submission_weighted_bayesian_svdpp_flipped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "627cf8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3, 2.3]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2.3] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e47e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
