{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SurpriseSVD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Surprise SVD"
      ],
      "metadata": {
        "id": "A52vRAGmvP7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "geICpVeEvSoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Surprise package"
      ],
      "metadata": {
        "id": "dB-LKtO0wdZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "ahnOOUDGwgEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "KWkssmLnvUjz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dLdDIWuN6jxj"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declare global parameters of data"
      ],
      "metadata": {
        "id": "7gC17EdGvWIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_users = 10000\n",
        "total_num_movies = 1000"
      ],
      "metadata": {
        "id": "dXZsN1iBvc3w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data parsing helper function declarations"
      ],
      "metadata": {
        "id": "ilLPAyu5wKzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_csv(csv_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  Extract the arrays of user indices, item indices and ratings listed in a .csv file\n",
        "\n",
        "  :param csv_path: path to .csv file to read from\n",
        "  :return: 3 arrays containing the users indices, the item indices and the observed ratings in order  \n",
        "  \"\"\"\n",
        "  df = pd.read_csv(csv_path)\n",
        "  # extract user and item indices from the Id label in the dataframe\n",
        "  df = df.join(df.Id.str.extract(r\"r(?P<User>\\d+)_c(?P<Item>\\d+)\").astype(int) - 1)\n",
        "  # extract user, item and prediction triplets from dataframe\n",
        "  users = df.User.values\n",
        "  items = df.Item.values\n",
        "  preds = df.Prediction.values\n",
        "  return users, items, preds"
      ],
      "metadata": {
        "id": "lxWEf_5rwMQy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Surprise SVD model"
      ],
      "metadata": {
        "id": "Ec2Q2Zo6xH7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct data in correct format\n",
        "users, items, preds = parse_csv(\"../data/data_train.csv\")\n",
        "ratings_dict = {'itemID': items, 'userID': users, 'rating': preds}\n",
        "df = pd.DataFrame(ratings_dict)\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
      ],
      "metadata": {
        "id": "fjPVpU1yxKvL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': list(range(2, 22, 2)),\n",
        "    'n_epochs': [20],\n",
        "    'lr_all': list(np.arange(0.001, 0.010, 0.001)),\n",
        "    'reg_all': list(np.arange(0.0, 1.0, 0.1))\n",
        "}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=10, n_jobs=-1, joblib_verbose=2)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# report and save the best parameters\n",
        "best_params = gs.best_params['rmse']\n",
        "print(f\"The minimum RMSE score is {gs.best_score['rmse']}\")\n",
        "print(f\"The parameters which give the best RMSE score are: {best_params}\")\n",
        "n_factors = best_params['n_factors']\n",
        "n_epochs = best_params['n_epochs']\n",
        "lr_all = best_params['lr_all']\n",
        "reg_all = best_params['reg_all']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hjoGoe9CGsD",
        "outputId": "9a192fef-405e-461c-ee21-e9b55f77e8a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0020673859959812\n",
            "{'n_factors': 2, 'n_epochs': 10, 'lr_all': 0.001, 'reg_all': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.6min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the submission the full set is set as the trainset\n",
        "trainset = data.build_full_trainset()\n",
        "# init SVD with the best params found in the param tuning\n",
        "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all, random_state=1234)\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)"
      ],
      "metadata": {
        "id": "V5S8KO9i96rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the needed users and items for submission\n",
        "pred_users, pred_items, _ = parse_csv('../data/sampleSubmission.csv')\n",
        "pred_ratings = list()\n",
        "df_ids = list()\n",
        "# use the trained model to extract the predictions for submission\n",
        "for user, item in zip(pred_users, pred_items):\n",
        "  df_ids.append(f\"r{user + 1}_c{item + 1}\")\n",
        "  pred_ratings.append(algo.predict(user, item, verbose=False).est)\n",
        "# save the prediction into a file in the agreed format\n",
        "df = pd.DataFrame({\"Id\": df_ids, \"Prediction\": pred_ratings})\n",
        "df.to_csv(f\"../results/surprise_svd_n_factors-{n_factors}_n_epochs-{n_epochs}_lr_all-{lr_all:.3f}_reg_all-{reg_all:.1f}_submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "DOhxZQ2U8wk9"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}