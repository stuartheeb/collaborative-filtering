{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SurpriseSVD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Surprise SVD"
      ],
      "metadata": {
        "id": "A52vRAGmvP7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ],
      "metadata": {
        "id": "geICpVeEvSoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Surprise package"
      ],
      "metadata": {
        "id": "dB-LKtO0wdZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "ahnOOUDGwgEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "KWkssmLnvUjz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLdDIWuN6jxj"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data parsing helper function declarations"
      ],
      "metadata": {
        "id": "ilLPAyu5wKzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_csv(csv_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  Extract the arrays of user indices, item indices and ratings listed in a .csv file\n",
        "\n",
        "  :param csv_path: path to .csv file to read from\n",
        "  :return: 3 arrays containing the users indices, the item indices and the observed ratings in order  \n",
        "  \"\"\"\n",
        "  df = pd.read_csv(csv_path)\n",
        "  # extract user and item indices from the Id label in the dataframe\n",
        "  df = df.join(df.Id.str.extract(r\"r(?P<User>\\d+)_c(?P<Item>\\d+)\").astype(int) - 1)\n",
        "  # extract user, item and prediction triplets from dataframe\n",
        "  users = df.User.values\n",
        "  items = df.Item.values\n",
        "  preds = df.Prediction.values\n",
        "  return users, items, preds"
      ],
      "metadata": {
        "id": "lxWEf_5rwMQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Surprise SVD model"
      ],
      "metadata": {
        "id": "Ec2Q2Zo6xH7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Dataset object with the data from data_train.csv."
      ],
      "metadata": {
        "id": "oZBBMd_37FWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct data in correct format\n",
        "users, items, preds = parse_csv(\"../data/data_train.csv\")\n",
        "ratings_dict = {'itemID': items, 'userID': users, 'rating': preds}\n",
        "df = pd.DataFrame(ratings_dict)\n",
        "# Defining a rating scale of [0, 5.5] gives a better result than a rating scale of [1, 5]\n",
        "reader = Reader(rating_scale=(0, 5.5))\n",
        "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
      ],
      "metadata": {
        "id": "fjPVpU1yxKvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare the parameters for the parameter tuning, run a grid search algorithm, and find and save the parameters which give the optimal RMSE score. The grid search splits the data into two subsets - one to fit the model with, and the other for validation. "
      ],
      "metadata": {
        "id": "05XVeJGm7MLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declare all parameters and their values to test in the grid search\n",
        "param_grid = {\n",
        "    'n_factors': list(range(2, 21, 2)),\n",
        "    'n_epochs': list(range(25, 101, 25)),\n",
        "    'lr_all': list(np.arange(0.001, 0.011, 0.001)),\n",
        "    'reg_all': list(np.arange(0.0, 1.1, 0.1))\n",
        "}\n",
        "# run grid search\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=10, n_jobs=-1, joblib_verbose=2)\n",
        "gs.fit(data)\n",
        "# save grid search results to dataframe for future reference\n",
        "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
        "results_df.to_csv(f\"../results/surprise_svd_grid_search_results.csv\", index=False)\n",
        "# report and save the best parameters\n",
        "best_params = gs.best_params['rmse']\n",
        "print(f\"The minimum RMSE score is {gs.best_score['rmse']}\")\n",
        "print(f\"The parameters which give the best RMSE score are: {best_params}\")\n",
        "n_factors = best_params['n_factors']\n",
        "n_epochs = best_params['n_epochs']\n",
        "lr_all = best_params['lr_all']\n",
        "reg_all = best_params['reg_all']"
      ],
      "metadata": {
        "id": "1hjoGoe9CGsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Table with the results of the parameter tuning:\")\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "gYZNB5r74Tsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now fit the model with the optimal parameters and the entire data set."
      ],
      "metadata": {
        "id": "tCx_Q2u47YTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the submission the full set is set as the trainset\n",
        "trainset = data.build_full_trainset()\n",
        "# init SVD with the best params found in the param tuning\n",
        "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all, random_state=1234)\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)"
      ],
      "metadata": {
        "id": "V5S8KO9i96rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the users and item ids needed for the submission file from sampleSubmission.csv, and use the fitted model to give predictions for them. Save the user ids, item ids and predictions to a .csv file for submission."
      ],
      "metadata": {
        "id": "XMAd4oDC72Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the needed users and items for submission\n",
        "pred_users, pred_items, _ = parse_csv('../data/sampleSubmission.csv')\n",
        "pred_ratings = list()\n",
        "df_ids = list()\n",
        "# use the trained model to extract the predictions for submission\n",
        "for user, item in zip(pred_users, pred_items):\n",
        "  df_ids.append(f\"r{user + 1}_c{item + 1}\")\n",
        "  pred_ratings.append(algo.predict(user, item, verbose=False).est)\n",
        "# save the prediction into a file in the agreed format\n",
        "df = pd.DataFrame({\"Id\": df_ids, \"Prediction\": pred_ratings})\n",
        "df.to_csv(f\"../results/surprise_svd_n_factors-{n_factors}_n_epochs-{n_epochs}_lr_all-{lr_all:.3f}_reg_all-{reg_all:.1f}_submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "DOhxZQ2U8wk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}