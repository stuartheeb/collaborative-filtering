{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A52vRAGmvP7o"
      },
      "source": [
        "# Improved SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook the improved SVD method for matrix completing is implemented on the CIL dataset.\n",
        "\n",
        "The sections \"Preprocess\", \"Run Improved SVD model\" and \"Create submission file\" can be run entirely and in sequence to produce the results. Run the \"Download data from Kaggle\" code block only if you are running on Colab."
      ],
      "metadata": {
        "id": "W9uEMYf_6SAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data from Kaggle"
      ],
      "metadata": {
        "id": "koTaTmKE59af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "import json\n",
        "\n",
        "kaggle_username = \"yuvalnis\" #@param {type:\"string\"}\n",
        "kaggle_api_key = \"1800d5a286834f0416c338c7bd7f6dee\" #@param {type:\"string\"}\n",
        "\n",
        "assert len(kaggle_username) > 0 and len(kaggle_api_key) > 0\n",
        "\n",
        "api_token = {\"username\": kaggle_username,\"key\": kaggle_api_key}\n",
        "\n",
        "with open('kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c cil-collaborative-filtering-2022\n",
        "\n",
        "!unzip -n cil-collaborative-filtering-2022.zip"
      ],
      "metadata": {
        "id": "dBFSZ9m25_d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geICpVeEvSoe"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB-LKtO0wdZD"
      },
      "source": [
        "### Install Surprise package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahnOOUDGwgEa"
      },
      "outputs": [],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWkssmLnvUjz"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLdDIWuN6jxj"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilLPAyu5wKzi"
      },
      "source": [
        "### Data parsing helper function declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxWEf_5rwMQy"
      },
      "outputs": [],
      "source": [
        "def parse_csv(csv_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  Extract the arrays of user indices, item indices and ratings listed in a .csv file\n",
        "\n",
        "  :param csv_path: path to .csv file to read from\n",
        "  :return: 3 arrays containing the users indices, the item indices and the observed ratings in order  \n",
        "  \"\"\"\n",
        "  df = pd.read_csv(csv_path)\n",
        "  # extract user and item indices from the Id label in the dataframe\n",
        "  df = df.join(df.Id.str.extract(r\"r(?P<User>\\d+)_c(?P<Item>\\d+)\").astype(int) - 1)\n",
        "  # extract user, item and prediction triplets from dataframe\n",
        "  users = df.User.values\n",
        "  items = df.Item.values\n",
        "  preds = df.Prediction.values\n",
        "  return users, items, preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec2Q2Zo6xH7D"
      },
      "source": [
        "## Run Improved SVD model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZBBMd_37FWC"
      },
      "source": [
        "Create the Dataset object with the data from data_train.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjPVpU1yxKvL"
      },
      "outputs": [],
      "source": [
        "# construct data in correct format\n",
        "users, items, preds = parse_csv(\"data_train.csv\")\n",
        "ratings_dict = {'itemID': items, 'userID': users, 'rating': preds}\n",
        "df = pd.DataFrame(ratings_dict)\n",
        "# Defining a rating scale of [0, 5.5] gives a better result than a rating scale of [1, 5]\n",
        "reader = Reader(rating_scale=(0, 5.5))\n",
        "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05XVeJGm7MLO"
      },
      "source": [
        "Declare the parameters for the parameter tuning, run a grid search algorithm, and find and save the parameters which give the optimal RMSE score. The grid search splits the data into two subsets - one to fit the model with, and the other for validation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hjoGoe9CGsD"
      },
      "outputs": [],
      "source": [
        "# declare all parameters and their values to test in the grid search\n",
        "param_grid = {\n",
        "    'n_factors': list(range(2, 21, 2)),\n",
        "    'n_epochs': list(range(25, 101, 25)),\n",
        "    'lr_all': list(np.arange(0.001, 0.011, 0.001)),\n",
        "    'reg_all': list(np.arange(0.0, 1.1, 0.1))\n",
        "}\n",
        "# run grid search\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=10, n_jobs=-1, joblib_verbose=2)\n",
        "gs.fit(data)\n",
        "# save grid search results to dataframe for future reference\n",
        "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
        "results_df.to_csv(f\"surprise_svd_grid_search_results.csv\", index=False)\n",
        "# report and save the best parameters\n",
        "best_params = gs.best_params['rmse']\n",
        "print(f\"The minimum RMSE score is {gs.best_score['rmse']}\")\n",
        "print(f\"The parameters which give the best RMSE score are: {best_params}\")\n",
        "n_factors = best_params['n_factors']\n",
        "n_epochs = best_params['n_epochs']\n",
        "lr_all = best_params['lr_all']\n",
        "reg_all = best_params['reg_all']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYZNB5r74Tsj"
      },
      "outputs": [],
      "source": [
        "print(f\"Table with the results of the parameter tuning:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCx_Q2u47YTu"
      },
      "source": [
        "Now fit the model with the optimal parameters and the entire data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5S8KO9i96rH"
      },
      "outputs": [],
      "source": [
        "# for the submission the full set is set as the trainset\n",
        "trainset = data.build_full_trainset()\n",
        "# init SVD with the best params found in the param tuning\n",
        "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all, random_state=1234)\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create submission file"
      ],
      "metadata": {
        "id": "rP7MDNmP6hYn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMAd4oDC72Ej"
      },
      "source": [
        "Extract the users and item ids needed for the submission file from sampleSubmission.csv, and use the fitted model to give predictions for them. Save the user ids, item ids and predictions to a .csv file for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOhxZQ2U8wk9"
      },
      "outputs": [],
      "source": [
        "# extract the needed users and items for submission\n",
        "pred_users, pred_items, _ = parse_csv('sampleSubmission.csv')\n",
        "pred_ratings = list()\n",
        "df_ids = list()\n",
        "# use the trained model to extract the predictions for submission\n",
        "for user, item in zip(pred_users, pred_items):\n",
        "  df_ids.append(f\"r{user + 1}_c{item + 1}\")\n",
        "  pred_ratings.append(algo.predict(user, item, verbose=False).est)\n",
        "# save the prediction into a file in the agreed format\n",
        "df = pd.DataFrame({\"Id\": df_ids, \"Prediction\": pred_ratings})\n",
        "df.to_csv(f\"surprise_svd_n_factors-{n_factors}_n_epochs-{n_epochs}_lr_all-{lr_all:.3f}_reg_all-{reg_all:.1f}_submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "improved_svd.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}