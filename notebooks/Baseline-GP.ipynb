{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fH1tDqYXODnd"
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DboqRCo_NhwK"
   },
   "source": [
    "This notebook includes the necessary code to run the baseline solution for the collaborative filtering Kaggle competition for the CIL 2022 course.\n",
    "\n",
    "You can run the baseline method in the 3 different modes available:\n",
    "\n",
    "1.   with parameter tuning.\n",
    "2.   with hard-coded parameter tuning result.\n",
    "3.   with the original parameters given by the course staff.\n",
    "\n",
    "Before you do, please run the entire \"Preprocess\" section. After that, choose one mode and run it. You can then create a submission file by running the section \"Create submission file\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Vt7acoKM8wP"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuOtt9PLLgSv"
   },
   "source": [
    "### Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CRyOpr5qLiUP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (1.5.12)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (6.1.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (4.63.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (1.26.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from kaggle) (2021.5.30)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from requests->kaggle) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from tqdm->kaggle) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from tqdm->kaggle) (0.4.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages (from importlib-resources->tqdm->kaggle) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"C:\\Users\\yuval\\anaconda3\\envs\\cil-runtime-terror\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 166, in authenticate\n",
      "    self.config_file, self.config_dir))\n",
      "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\yuval\\.kaggle. Or use the environment method.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "\n",
    "import json\n",
    "\n",
    "kaggle_username = \"yuvalnis\" #@param {type:\"string\"}\n",
    "kaggle_api_key = \"1800d5a286834f0416c338c7bd7f6dee\" #@param {type:\"string\"}\n",
    "\n",
    "assert len(kaggle_username) > 0 and len(kaggle_api_key) > 0\n",
    "\n",
    "api_token = {\"username\": kaggle_username,\"key\": kaggle_api_key}\n",
    "\n",
    "with open('kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!mv kaggle.json ~/.kaggle/kaggle.json\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c cil-collaborative-filtering-2022\n",
    "\n",
    "!unzip -n cil-collaborative-filtering-2022.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUIuYSCENCk1"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ir8e-ogLMS0B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyVtWL1vCipD"
   },
   "source": [
    "## Declare global parameters of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hUfftTI_Cft1"
   },
   "outputs": [],
   "source": [
    "total_num_users = 10000\n",
    "total_num_movies = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogmuKPI_UzVc"
   },
   "source": [
    "## Data parsing helper function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Dm4_OA6-VPJw"
   },
   "outputs": [],
   "source": [
    "def parse_csv(csv_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "  \"\"\"\n",
    "  Extract the arrays of user indices, item indices and ratings listed in a .csv file\n",
    "\n",
    "  :param csv_path: path to .csv file to read from\n",
    "  :return: 3 arrays containing the users indices, the item indices and the observed ratings in order  \n",
    "  \"\"\"\n",
    "  df = pd.read_csv(csv_path)\n",
    "  # extract user and item indices from the Id label in the dataframe\n",
    "  df = df.join(df.Id.str.extract(r\"r(?P<User>\\d+)_c(?P<Item>\\d+)\").astype(int) - 1)\n",
    "  # extract user, item and prediction triplets from dataframe\n",
    "  users = df.User.values\n",
    "  items = df.Item.values\n",
    "  preds = df.Prediction.values\n",
    "  return users, items, preds\n",
    "\n",
    "def construct_ratings_matrix(\n",
    "    users: np.ndarray,\n",
    "    items: np.ndarray,\n",
    "    ratings: np.ndarray,\n",
    "    n_users: int,\n",
    "    n_items: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"\n",
    "  Constructs the ratings matrix with NaN values where no rating was observed\n",
    "\n",
    "  :param users: array of user indices\n",
    "  :param items: array of item indices\n",
    "  :param predictions: array of ratings per user-item pair\n",
    "  :param n_users: total number of users\n",
    "  :param n_items: total number of items\n",
    "  :return: the ratings matrix and the observed ratings mask\n",
    "  \"\"\"\n",
    "  ratings_matrix = np.zeros((n_users, n_items))\n",
    "  observed_mask = np.full((n_users, n_items), fill_value=False)\n",
    "  for r, c, v in zip(users, items, ratings):\n",
    "    observed_mask[r, c] = True\n",
    "    ratings_matrix[r][c] = v\n",
    "\n",
    "  ratings_matrix[~observed_mask] = np.nan\n",
    "\n",
    "  return ratings_matrix, observed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pXPEMw24bAY"
   },
   "source": [
    "## Model function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BKwuoKmfORj9"
   },
   "outputs": [],
   "source": [
    "def KAA_splicer(covmat, selection_A):\n",
    "  assert(selection_A.shape[0] == covmat.shape[0])\n",
    "  assert(selection_A.shape[0] == covmat.shape[1])\n",
    "  temp = covmat[:, selection_A]\n",
    "  temp = temp[selection_A, :]\n",
    "  return temp\n",
    "\n",
    "def KXA_splicer(covmat, selection_A):\n",
    "  assert(selection_A.shape[0] == covmat.shape[0])\n",
    "  assert(selection_A.shape[0] == covmat.shape[1])\n",
    "  temp = covmat[:, selection_A]\n",
    "  temp = temp[np.logical_not(selection_A), :]\n",
    "  return temp\n",
    "\n",
    "def MUA_splicer(mu, selection_A):\n",
    "  assert(selection_A.shape[0] == mu.shape[0])\n",
    "  temp = mu[np.logical_not(selection_A)]\n",
    "  return temp\n",
    "\n",
    "def gauss_kernel(a, b, bandwidth):\n",
    "  return np.exp(-(np.linalg.norm(a-b)**2)/bandwidth**2)\n",
    "\n",
    "#X is the recommender system Matrix and entry_mask masks the existend entries\n",
    "def gp_imputation(X, bandwidth, noise):\n",
    "  #Xcombined = np.concatenate((X, Xtest))\n",
    "  Xcombined = X\n",
    "  maskedXcombined = np.ma.array(Xcombined, mask = np.logical_not(np.isnan(Xcombined)))\n",
    "  mean = np.nanmean(Xcombined, axis = 0)\n",
    "  cov = np.zeros((Xcombined.shape[1], Xcombined.shape[1]))\n",
    "  notnan_mask = np.logical_not(np.isnan(Xcombined))\n",
    "  for i in range(Xcombined.shape[1]):\n",
    "    localmask = notnan_mask[:, i]\n",
    "    #cov[i, i] = (np.matmul(Xcombined[localmask, i], Xcombined[localmask, i])**2+1)**2\n",
    "    cov[i, i] = np.var(Xcombined[localmask, i])\n",
    "    #cov[i, i] = 1.0\n",
    "    for j in range(i + 1, Xcombined.shape[1]):\n",
    "      localmask = notnan_mask[:, i] & notnan_mask[:, j]\n",
    "      t1 = Xcombined[localmask, i]\n",
    "      t2 = Xcombined[localmask, j]\n",
    "      #temp = np.cov([t1, t2])\n",
    "      #cov[i, j] = (np.matmul(t1, t2) + 1)**2\n",
    "      #cov[i, j] = temp[0, 1]\n",
    "      cov[i, j] = gauss_kernel(t1, t2, bandwidth)\n",
    "      cov[j, i] = cov[i, j]\n",
    "  Xcombined_new = np.copy(Xcombined)\n",
    "\n",
    "  print(Xcombined.shape)\n",
    "\n",
    "  for index, features in enumerate(Xcombined):\n",
    "    selection_A = notnan_mask[index, :]\n",
    "    mu = MUA_splicer(mean, selection_A)\n",
    "    kxa = KXA_splicer(cov, selection_A)\n",
    "    kaa = KAA_splicer(cov, selection_A)\n",
    "    ya = Xcombined[index, selection_A]\n",
    "    #print(mu.shape)\n",
    "    #print(kxa.shape)\n",
    "    #print(kaa.shape)\n",
    "    #print(ya.T.shape)\n",
    "    pred = mu + np.matmul(kxa, np.linalg.solve(kaa + np.identity(kaa.shape[0]) * noise**2, ya.T))\n",
    "    #print(pred)\n",
    "    #assert(False)\n",
    "    for i in range(Xcombined.shape[1]):\n",
    "      curr = 0\n",
    "      if np.logical_not(notnan_mask[index, i]):\n",
    "        Xcombined_new[index, i] = pred[curr]\n",
    "        curr += 1\n",
    "  #assert(not np.any(np.isnan(Xcombined_new)))\n",
    "  return Xcombined_new\n",
    "\n",
    "\n",
    "def normalize(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "  \"\"\"\n",
    "  Normalizes the input data matrix per item (column). NaN entries are disregarded and are set to zero.  \n",
    "\n",
    "  :param data: matrix to normalize\n",
    "  :return: the normalized input matrix, the column-wise mean and the column-wise standard deviation\n",
    "  \"\"\"\n",
    "  # compute mean and std and normalized the matrix with NaN values\n",
    "  mean = np.nanmean(data, axis=0, keepdims=True)\n",
    "  std = np.nanstd(data, axis=0, keepdims=True)\n",
    "  normed_data = (data - mean) / std\n",
    "  # set the non-observed entries to 0\n",
    "  normed_data = gp_imputation(normed_data, 0.1, 1.0)\n",
    "  return normed_data, mean, std\n",
    "\n",
    "\n",
    "def denormalize(data: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "  \"\"\"\n",
    "  Denormalizes the input data matrix per item (column) by performing the inverse operation of the normalize function  \n",
    "\n",
    "  :param data: matrix to denormalize\n",
    "  :param mean: the column-wise mean of the unnormalized matrix\n",
    "  :param std: the column-wise std of the unnormalized matrix\n",
    "  :return: the denormalized matrix\n",
    "  \"\"\"\n",
    "  return (data * std) + mean\n",
    "\n",
    "\n",
    "def SVD(A: np.ndarray, k: int) -> np.ndarray:\n",
    "  \"\"\"\n",
    "  Computes the singular value decomposition of the input matrix, projected on\n",
    "  the subspace defined by the k largest singular values, as a 3-tuple\n",
    "\n",
    "  :param A: matrix to decompose\n",
    "  :param k: number of the largest singular values\n",
    "  :return: the projected singular value decomposition of A\n",
    "  \"\"\"\n",
    "  assert(k <= min(A.shape)), \"k should be no greater than the number of users or items.\"\n",
    "  U, S, VT = np.linalg.svd(A, full_matrices=False)\n",
    "  return U[:, :k], np.diag(S[:k]), VT[:k, :]\n",
    "\n",
    "\n",
    "def RMSE(x: np.ndarray, y: np.ndarray, mask: np.ndarray) -> float:\n",
    "  return np.sqrt(np.nansum(mask * (x - y) ** 2) / np.sum(mask))\n",
    "\n",
    "\n",
    "def ALS(\n",
    "    data: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    U: np.ndarray,\n",
    "    VT: np.ndarray,\n",
    "    n_latent_factors: int,\n",
    "    regularization_param: float,\n",
    "    n_iterations: int\n",
    ") -> np.ndarray:\n",
    "  regularizer = regularization_param * np.eye(n_latent_factors)\n",
    "\n",
    "  with tqdm(total=n_iterations * (np.sum(mask.shape))) as pbar:\n",
    "    rmse_score = RMSE(data, U @ VT, mask)\n",
    "    pbar.set_description(f\"Initial RMSE score is {rmse_score:.4f}\")\n",
    "    for iter in range(n_iterations):\n",
    "      for i, Ri in enumerate(mask):\n",
    "        U[i] = np.linalg.solve(\n",
    "            np.dot(VT, np.dot(np.diag(Ri), VT.T)) + regularizer,\n",
    "            (np.dot(VT, np.dot(np.diag(Ri), data[i].T))).T\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "      for j, Rj in enumerate(mask.T):\n",
    "        VT[:,j] = np.linalg.solve(\n",
    "            np.dot(U.T, np.dot(np.diag(Rj), U)) + regularizer,\n",
    "            np.dot(U.T, np.dot(np.diag(Rj), data[:, j]))\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "      rmse_score = RMSE(data, U @ VT, mask)\n",
    "      pbar.set_description(f\"At iteration #{iter + 1} the RMSE score is {rmse_score:.4f}\")\n",
    "\n",
    "  return U @ VT\n",
    "\n",
    "\n",
    "def baseline(\n",
    "    data: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    n_latent_factors: int,\n",
    "    regularization_param: float,\n",
    "    n_iterations: int\n",
    ") -> np.ndarray:\n",
    "  \"\"\"\n",
    "  Runs the baseline (normalization, SVD, ALS and then denormalization) method\n",
    "\n",
    "  :param data: the ratings matrix\n",
    "  :param mask: the matrix of observed ratings\n",
    "  :param n_latent_factors: the number of latent factor to use\n",
    "  :param regularization_param: the regularizer (lambda) to use in the ALS steps\n",
    "  :param n_iterations: the number of ALS iterations to do\n",
    "  :return: the predicted ratings matrix\n",
    "  \"\"\"\n",
    "  norm_data, data_mean, data_std = normalize(data)\n",
    "  U, _, VT = SVD(norm_data, n_latent_factors)\n",
    "  pred_ratings = ALS(norm_data, mask, U, VT, n_latent_factors, regularization_param, n_iterations)\n",
    "  return denormalize(pred_ratings, data_mean, data_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4Z1G3wBN3tx"
   },
   "source": [
    "# Setup baseline model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JavV6DBXd88N"
   },
   "source": [
    "## With parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skd9EIBeeECS"
   },
   "source": [
    "We tune the parameters of the baseline model using the grid search method over pairs of values for the number of latent factors used in SVD and ALS, and the regularization parameter used in ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeTVL-t8eHbZ"
   },
   "source": [
    "Split the data into train and test subsets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtLE_TyzeGxj"
   },
   "outputs": [],
   "source": [
    "users, items, preds = parse_csv('../data/data_train.csv')\n",
    "# determine a random test set for the parameter tuning\n",
    "train_users, test_users, train_items, test_items, train_preds, test_preds = \\\n",
    "  train_test_split(users, items, preds, test_size=0.1, random_state=42)\n",
    "# construct ratings and masks for train and test sets\n",
    "train_ratings, train_mask = construct_ratings_matrix(\n",
    "    train_users, train_items, train_preds, total_num_users, total_num_movies\n",
    ")\n",
    "test_ratings, test_mask = construct_ratings_matrix(\n",
    "    test_users, test_items, test_preds, total_num_users, total_num_movies\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApRXRBRYyh9M"
   },
   "source": [
    "Declare ranges of parameters to tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cU3VzDJylld"
   },
   "outputs": [],
   "source": [
    "reg_param_vals = [0.1, 0.25, 0.5]\n",
    "latent_dim_vals = range(2, 17, 2)\n",
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP9Ftmv0yn21"
   },
   "source": [
    "Run a grid search algorithm to check the RMSE score on the validation subset given a parameter set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1fcMusceP66"
   },
   "outputs": [],
   "source": [
    "results: List[Tuple[float, int, float, float]] = list()\n",
    "best_val_rmse = None\n",
    "with tqdm(total=len(reg_param_vals) * len(latent_dim_vals)) as pbar:\n",
    "  for i, reg in enumerate(reg_param_vals):\n",
    "    for j, latent_dim in enumerate(latent_dim_vals):\n",
    "      # compute predicted ratings with parameter pair\n",
    "      pred_ratings = baseline(train_ratings, train_mask, latent_dim, reg, n_iterations)\n",
    "      # compute and report RMSE train and test scores\n",
    "      train_rmse = RMSE(pred_ratings, train_ratings, train_mask)\n",
    "      test_rmse = RMSE(pred_ratings, test_ratings, test_mask)\n",
    "      print(f\"Regularizing parameter: {reg:.1f}, \" \\\n",
    "            f\"number of latent factors: {latent_dim}, \" \\\n",
    "            f\"train RMSE score: {train_rmse:.4f}, \" \\\n",
    "            f\"test RMSE score: {test_rmse:.4f}\")\n",
    "      # save RMSE scores in table\n",
    "      results.append((reg, latent_dim, train_rmse, test_rmse))\n",
    "\n",
    "      best_val_rmse = test_rmse if (best_val_rmse is None or test_rmse < best_val_rmse) else best_val_rmse\n",
    "      pbar.update(1)\n",
    "      pbar.set_description(f\"(regularization param: {reg:.2f}, latent dim: {latent_dim}): minimal RMSE score on validation set is {best_val_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBKAyWAWy2Q8"
   },
   "source": [
    "Save results of the grid search to a .csv file for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pmy4xJKky3g4"
   },
   "outputs": [],
   "source": [
    "print(f\"Saving the RMSE scores table to file...\")\n",
    "results_df = pd.DataFrame({\n",
    "    \"Regularization parameter\": [reg_param for reg_param, _, _, _ in results],\n",
    "    \"Number of latent factors\": [n_latent_factors for _, n_latent_factors, _, _ in results],\n",
    "    \"fit RMSE\": [fit_rmse for _, _, fit_rmse, _ in results],\n",
    "    \"validation RMSE\": [val_rmse for _, _, _, val_rmse in results]\n",
    "})\n",
    "results_df.to_csv(f\"../results/baseline_param_tuning_results_reg.csv\", index=False)\n",
    "print(f\"Done!\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hv4duK_ey9gG"
   },
   "source": [
    "Extract the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlRZ5jAsy91o"
   },
   "outputs": [],
   "source": [
    "regularization_param, n_latent_factors, _, min_val_rmse = min(results, key=(lambda t: t[3]))\n",
    "print(f\"The optimal regularization parameter is {regularization_param:.2f}\")\n",
    "print(f\"The optimal number of latent factors is {n_latent_factors}\")\n",
    "print(f\"The optimal validation RMSE is {min_val_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyQ_tyKfeEp1"
   },
   "source": [
    "## Hardcoded optimal parameters (skip parameter tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHyxckHDik0B"
   },
   "source": [
    "Declare baseline parameters found after the parameter tuning algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7jYRVsEiUix"
   },
   "outputs": [],
   "source": [
    "n_latent_factors = 3\n",
    "regularization_param = 0.1\n",
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WN4249fS5yr"
   },
   "source": [
    "## With original parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY6KsWZj9Pqm"
   },
   "source": [
    "Declare baseline parameters used tp set the Kaggle competition baseline score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "X6PF6jioXstU"
   },
   "outputs": [],
   "source": [
    "n_latent_factors = 3\n",
    "regularization_param = 0.1\n",
    "n_iterations = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsqr8_Wmzuc4"
   },
   "source": [
    "# Run baseline model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tVllg-N8zyiB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b2ea5b8e4e48bc942ab9da71f90236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "users, items, preds = parse_csv('data_train.csv')\n",
    "ratings, mask = construct_ratings_matrix(users, items, preds, total_num_users, total_num_movies)\n",
    "pred_ratings = baseline(ratings, mask, n_latent_factors, regularization_param, n_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI6Me2qi4mc7"
   },
   "source": [
    "# Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "v3eDJ2Kz2LvQ"
   },
   "outputs": [],
   "source": [
    "pred_users, pred_items, _ = parse_csv('sampleSubmission.csv')\n",
    "df = pd.DataFrame({\n",
    "    \"Id\": [f\"r{r + 1}_c{c + 1}\" for r, c in zip(pred_users, pred_items)],\n",
    "    \"Prediction\": [pred_ratings[r, c] for r, c in zip(pred_users, pred_items)]\n",
    "})\n",
    "df.to_csv(f\"baseline_gp_reg-{regularization_param:.2f}_k-{n_latent_factors}_iters-{n_iterations}_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline-GP.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
