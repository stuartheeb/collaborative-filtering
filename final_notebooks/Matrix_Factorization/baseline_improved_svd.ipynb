{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A52vRAGmvP7o"
      },
      "source": [
        "# Baseline method with SVD replaced with Improved SVD"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook the baseline method (SVD -> ALS) is extended by replacing the initialization and SVD step with Improved SVD.\n",
        "\n",
        "The sections \"Preprocess\", \"Run Improved SVD + ALS model\" and \"Create submission file\" can be run entirely and in sequence to produce the results. Run the \"Download data from Kaggle\" code block only if you are running on Colab."
      ],
      "metadata": {
        "id": "geBb6tcYw9O2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data from Kaggle"
      ],
      "metadata": {
        "id": "wy0OcNxdzOEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "import json\n",
        "\n",
        "kaggle_username = \"yuvalnis\" #@param {type:\"string\"}\n",
        "kaggle_api_key = \"1800d5a286834f0416c338c7bd7f6dee\" #@param {type:\"string\"}\n",
        "\n",
        "assert len(kaggle_username) > 0 and len(kaggle_api_key) > 0\n",
        "\n",
        "api_token = {\"username\": kaggle_username,\"key\": kaggle_api_key}\n",
        "\n",
        "with open('kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c cil-collaborative-filtering-2022\n",
        "\n",
        "!unzip -n cil-collaborative-filtering-2022.zip"
      ],
      "metadata": {
        "id": "vD86ZFCqzLgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geICpVeEvSoe"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB-LKtO0wdZD"
      },
      "source": [
        "### Install Surprise package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahnOOUDGwgEa"
      },
      "outputs": [],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWkssmLnvUjz"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLdDIWuN6jxj"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSs1C_Zd4ntR"
      },
      "source": [
        "### Declare global parameters of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dghb64dR4o_E"
      },
      "outputs": [],
      "source": [
        "total_num_users = 10000\n",
        "total_num_movies = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilLPAyu5wKzi"
      },
      "source": [
        "### Data parsing helper function declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxWEf_5rwMQy"
      },
      "outputs": [],
      "source": [
        "def parse_csv(csv_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  Extract the arrays of user indices, item indices and ratings listed in a .csv file\n",
        "\n",
        "  :param csv_path: path to .csv file to read from\n",
        "  :return: 3 arrays containing the users indices, the item indices and the observed ratings in order  \n",
        "  \"\"\"\n",
        "  df = pd.read_csv(csv_path)\n",
        "  # extract user and item indices from the Id label in the dataframe\n",
        "  df = df.join(df.Id.str.extract(r\"r(?P<User>\\d+)_c(?P<Item>\\d+)\").astype(int) - 1)\n",
        "  # extract user, item and prediction triplets from dataframe\n",
        "  users = df.User.values\n",
        "  items = df.Item.values\n",
        "  preds = df.Prediction.values\n",
        "  return users, items, preds\n",
        "\n",
        "\n",
        "def construct_ratings_matrix(\n",
        "    users: np.ndarray,\n",
        "    items: np.ndarray,\n",
        "    ratings: np.ndarray,\n",
        "    n_users: int,\n",
        "    n_items: int\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"\n",
        "  Constructs the ratings matrix with NaN values where no rating was observed\n",
        "\n",
        "  :param users: array of user indices\n",
        "  :param items: array of item indices\n",
        "  :param predictions: array of ratings per user-item pair\n",
        "  :param n_users: total number of users\n",
        "  :param n_items: total number of items\n",
        "  :return: the ratings matrix and the observed ratings mask\n",
        "  \"\"\"\n",
        "  ratings_matrix = np.zeros((n_users, n_items))\n",
        "  observed_mask = np.full((n_users, n_items), fill_value=False)\n",
        "  for r, c, v in zip(users, items, ratings):\n",
        "    observed_mask[r, c] = True\n",
        "    ratings_matrix[r][c] = v\n",
        "\n",
        "  ratings_matrix[~observed_mask] = np.nan\n",
        "\n",
        "  return ratings_matrix, observed_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnALntEU3Up6"
      },
      "source": [
        "### Model function declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CaquZYf3SrD"
      },
      "outputs": [],
      "source": [
        "def RMSE(x: np.ndarray, y: np.ndarray, mask: np.ndarray) -> float:\n",
        "  return np.sqrt(np.nansum(mask * (x - y) ** 2) / np.sum(mask))\n",
        "\n",
        "\n",
        "def ALS(\n",
        "    data: np.ndarray,\n",
        "    mask: np.ndarray,\n",
        "    U: np.ndarray,\n",
        "    VT: np.ndarray,\n",
        "    n_latent_factors: int,\n",
        "    regularization_param: float,\n",
        "    n_iterations: int\n",
        ") -> np.ndarray:\n",
        "  regularizer = regularization_param * np.eye(n_latent_factors)\n",
        "\n",
        "  with tqdm(total=n_iterations * (np.sum(mask.shape))) as pbar:\n",
        "    rmse_score = RMSE(data, U @ VT, mask)\n",
        "    pbar.set_description(f\"Initial RMSE score is {rmse_score:.4f}\")\n",
        "    for iter in range(n_iterations):\n",
        "      for i, Ri in enumerate(mask):\n",
        "        U[i] = np.linalg.solve(\n",
        "            np.dot(VT, np.dot(np.diag(Ri), VT.T)) + regularizer,\n",
        "            (np.dot(VT, np.dot(np.diag(Ri), data[i].T))).T\n",
        "        )\n",
        "        pbar.update(1)\n",
        "\n",
        "      for j, Rj in enumerate(mask.T):\n",
        "        VT[:,j] = np.linalg.solve(\n",
        "            np.dot(U.T, np.dot(np.diag(Rj), U)) + regularizer,\n",
        "            np.dot(U.T, np.dot(np.diag(Rj), data[:, j]))\n",
        "        )\n",
        "        pbar.update(1)\n",
        "\n",
        "      rmse_score = RMSE(data, U @ VT, mask)\n",
        "      pbar.set_description(f\"At iteration #{iter + 1} the RMSE score is {rmse_score:.4f}\")\n",
        "\n",
        "  return U @ VT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec2Q2Zo6xH7D"
      },
      "source": [
        "## Run Improved SVD + ALS model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare parameters for Improved SVD and ALS. These parameters were found to be optimal on the standalone Improved SVD method and the standalone baseline method:"
      ],
      "metadata": {
        "id": "CMUaEAQLuawp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxkFVZwZ6NHy"
      },
      "outputs": [],
      "source": [
        "n_factors = 3\n",
        "svd_lr_all = 0.005\n",
        "svd_reg_all = 0.1\n",
        "svd_n_epochs = 100\n",
        "als_reg = 0.1\n",
        "als_n_iterations = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZBBMd_37FWC"
      },
      "source": [
        "Parse the data from the data_train.csv file and construct the ratings matrix and mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjPVpU1yxKvL"
      },
      "outputs": [],
      "source": [
        "# construct data in correct format\n",
        "users, items, preds = parse_csv(\"data_train.csv\")\n",
        "ratings, mask = construct_ratings_matrix(users, items, preds, total_num_users, total_num_movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCx_Q2u47YTu"
      },
      "source": [
        "Fit the Improved SVD model with the optimal parameters and the entire data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5S8KO9i96rH"
      },
      "outputs": [],
      "source": [
        "ratings_dict = {'itemID': items, 'userID': users, 'rating': preds}\n",
        "df = pd.DataFrame(ratings_dict)\n",
        "reader = Reader(rating_scale=(0.5, 5.5))\n",
        "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
        "# for the submission the full set is set as the trainset\n",
        "trainset = data.build_full_trainset()\n",
        "# init SVD with the best params found in the param tuning and with the n_factors optimal for regular SVD + ALS\n",
        "algo = SVD(n_factors=n_factors, n_epochs=svd_n_epochs, lr_all=svd_lr_all, reg_all=svd_reg_all, random_state=1234)\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract $U$ and $V^T$ from the fitted Improved SVD model and input them to the ALS method:"
      ],
      "metadata": {
        "id": "e3RbviyTu7o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "U = np.copy(algo.pu)\n",
        "VT = np.copy(algo.qi.T)"
      ],
      "metadata": {
        "id": "th0FGmebtP-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ratings = ALS(ratings, mask, U, VT, n_factors, als_reg, als_n_iterations)\n",
        "print(f\"Validation RMSE: {RMSE(pred_ratings, ratings, mask)}\")"
      ],
      "metadata": {
        "id": "MrXk7w-0fauA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create submission file"
      ],
      "metadata": {
        "id": "O26-E66U0JLa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMAd4oDC72Ej"
      },
      "source": [
        "Extract the users and item ids needed for the submission file from sampleSubmission.csv, and use the fitted model to give predictions for them. Save the user ids, item ids and predictions to a .csv file for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOhxZQ2U8wk9"
      },
      "outputs": [],
      "source": [
        "# extract the needed users and items for submission\n",
        "pred_users, pred_items, _ = parse_csv('sampleSubmission.csv')\n",
        "# save the prediction into a file in the agreed format\n",
        "df = pd.DataFrame({\n",
        "    \"Id\": [f\"r{r + 1}_c{c + 1}\" for r, c in zip(pred_users, pred_items)],\n",
        "    \"Prediction\": [pred_ratings[r, c] for r, c in zip(pred_users, pred_items)]\n",
        "})\n",
        "df.to_csv(f\"baseline_improved_svd_submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "baseline_improved_svd.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}