{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b319f75",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5737192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install packages to apply SVD and Bayesian Factorization Machine\n",
    "!pip install surprise\n",
    "\n",
    "!pip install myfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83dc77",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbe7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To apply SVD\n",
    "import surprise\n",
    "\n",
    "# To apply Factorization Machines\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "from myfm.utils.encoders import(DataFrameEncoder,MultipleValuesToSparseEncoder,CategoryValueToSparseEncoder)\n",
    "\n",
    "# To do train-test split for evaluation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14d436",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3563ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Extract users, movies and ratings from raw data\n",
    "def extract_users_items_predictions(data_pd):\n",
    "    users, movies = \\\n",
    "        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n",
    "    predictions = data_pd.Prediction.values\n",
    "    return users, movies, predictions\n",
    "\n",
    "#Load raw data\n",
    "data_pd = pd.read_csv('../data/data_train.csv')\n",
    "\n",
    "#Do Train-Test Split\n",
    "train, val = train_test_split(data_pd, test_size=0.1,random_state=42)\n",
    "\n",
    "#Extract users, movies and ratings from raw data\n",
    "total_users, total_movies, total_pred = extract_users_items_predictions(data_pd)\n",
    "train_users, train_movies, train_pred = extract_users_items_predictions(train)\n",
    "val_users, val_movies, val_pred = extract_users_items_predictions(val)\n",
    "\n",
    "#Store total data\n",
    "ratings_dict_total = {'userID': total_users,'movieID': total_movies,'rating': total_pred}\n",
    "df_total = pd.DataFrame(ratings_dict_total)\n",
    "\n",
    "#Store train data\n",
    "ratings_dict_train = {'userID': train_users,'movieID': train_movies,'rating': train_pred}\n",
    "df_train = pd.DataFrame(ratings_dict_train)\n",
    "\n",
    "#Store validation data\n",
    "ratings_dict_test = {'userID': val_users,'movieID': val_movies,'rating': val_pred}\n",
    "df_test = pd.DataFrame(ratings_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f42c9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630</td>\n",
       "      <td>740</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5909</td>\n",
       "      <td>785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7720</td>\n",
       "      <td>545</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7629</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2519</td>\n",
       "      <td>934</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059251</th>\n",
       "      <td>153</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059252</th>\n",
       "      <td>8739</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059253</th>\n",
       "      <td>9122</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059254</th>\n",
       "      <td>8104</td>\n",
       "      <td>574</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059255</th>\n",
       "      <td>597</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059256 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID  movieID  rating\n",
       "0           630      740       4\n",
       "1          5909      785       2\n",
       "2          7720      545       4\n",
       "3          7629       45       3\n",
       "4          2519      934       5\n",
       "...         ...      ...     ...\n",
       "1059251     153       92       5\n",
       "1059252    8739      213       5\n",
       "1059253    9122      108       2\n",
       "1059254    8104      574       5\n",
       "1059255     597      101       5\n",
       "\n",
       "[1059256 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bad323",
   "metadata": {},
   "source": [
    "## Get implicit user/movie Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d81506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Code adapted from https://github.com/tohtsky/myFM/blob/main/examples/ml-100k-extended.ipynb'''\n",
    "\n",
    "#Utility function to convert list to str\n",
    "def string_agg(int_list) -> str:\n",
    "    return ','.join([str(y) for y in int_list])\n",
    "\n",
    "def aggr(int_list):\n",
    "    return [y for y in int_list]\n",
    "\n",
    "#Get & Store Implicit Features\n",
    "user_f = pd.DataFrame(np.arange(10000),columns=['userID'])\n",
    "user_f['implicit_features'] = df_train.groupby('userID').movieID.agg(string_agg).reindex(user_f.index).fillna('')\n",
    "user_f['rating_features'] = df_train.groupby('userID').rating.agg(aggr).reindex(user_f.index).fillna('')\n",
    "user_f['user_metadata'] = user_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "movie_f = pd.DataFrame(np.arange(1000),columns=['movieID'])\n",
    "movie_f['implicit_features'] = df_train.groupby('movieID').userID.agg(string_agg).reindex(movie_f.index).fillna('')\n",
    "movie_f['rating_features'] = df_train.groupby('movieID').rating.agg(aggr).reindex(movie_f.index).fillna('')\n",
    "movie_f['movie_metadata'] = movie_f[['implicit_features', 'rating_features']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc42151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import scipy.sparse as sps\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "\n",
    "class WeightMultipleValuesToSparseEncoder(CategoryValueToSparseEncoder[str]):\n",
    "    \"\"\"The class to N-hot encode a List of items into a sparse matrix representation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        items: Iterable[str],\n",
    "        min_freq: int = 1,\n",
    "        sep: str = \",\",\n",
    "        normalize: bool = True,\n",
    "        handle_unknown: Literal[\"create\", \"ignore\", \"raise\"] = \"create\",\n",
    "    ):\n",
    "        \"\"\"Construct the encoder by providing a list of strings,\n",
    "        each of which is a list of strings concatenated by `sep`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        items : Iterable[str]\n",
    "            Iterable of strings, each of which is a concatenated list of possibly multiple items.\n",
    "        min_freq : int, optional\n",
    "            The minimal frequency for an item to be retained in the known items list, by default 1.\n",
    "        sep: str, optional\n",
    "            Tells how to separate string back into a list. Defaults to `','`.\n",
    "        normalize: bool, optional\n",
    "            If `True`, non-zero entry in the encoded matrix will have `1 / N ** 0.5`,\n",
    "            where `N` is the number of non-zero entries in that row. Defaults to `True`.\n",
    "        handle_unknown: Literal[\"create\", \"ignore\", \"raise\"], optional\n",
    "            How to handle previously unseen values during encoding.\n",
    "            If \"create\", then there is a single category named \"__UNK__\" for unknown values,\n",
    "            ant it is treated as 0th category.\n",
    "            If \"ignore\", such an item will be ignored.\n",
    "            If \"raise\", a `KeyError` is raised.\n",
    "            Defaults to \"create\".\n",
    "        \"\"\"\n",
    "        items_flatten = [\n",
    "            y for x in items for y in set(x['implicit_features'].split(sep)) if y\n",
    "        ]  # ignore empty string.\n",
    "        self.sep = sep\n",
    "        self.normalize = normalize\n",
    "        super().__init__(\n",
    "            items_flatten, min_freq=min_freq, handle_unknown=handle_unknown\n",
    "        )\n",
    "\n",
    "    def to_sparse(self, items: Iterable[str]) -> sps.csr_matrix:\n",
    "        indptr = [0]\n",
    "        indices = []\n",
    "        data = []\n",
    "        n_row = 0\n",
    "        cursor = 0\n",
    "        for row in items:\n",
    "            n_row += 1\n",
    "            items = row['implicit_features'].split(self.sep)\n",
    "            indices_local = sorted(\n",
    "                list(\n",
    "                    {\n",
    "                        index\n",
    "                        for index in [self._get_index(v) for v in items if v]\n",
    "                        if index is not None\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if not indices_local:\n",
    "                indptr.append(cursor)\n",
    "                continue\n",
    "            n = len(indices_local)\n",
    "            #value = 1.0 / (float(n) ** 0.5) if self.normalize else 1.0\n",
    "            indices.extend(indices_local)\n",
    "            #data.extend([value] * n)\n",
    "            weights = row['rating_features']\n",
    "            total_weights = sum(weights)\n",
    "            values = []\n",
    "            for i in range(n):\n",
    "                values.append(weights[i] / total_weights)\n",
    "            data.extend(values)\n",
    "                \n",
    "            cursor += n\n",
    "            indptr.append(cursor)\n",
    "        return sps.csr_matrix(\n",
    "            (data, indices, indptr),\n",
    "            shape=(n_row, len(self)),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e47d8",
   "metadata": {},
   "source": [
    "# Transform Data in myfm Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39cee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create User Encoder\n",
    "user_encoder = DataFrameEncoder().add_column(\n",
    "    'userID', CategoryValueToSparseEncoder(user_f.userID)\n",
    "    )\n",
    "\n",
    "user_encoder.add_column(\n",
    "        'user_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(user_f.user_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Movie Encoder\n",
    "movie_encoder = DataFrameEncoder().add_column(\n",
    "    'movieID', CategoryValueToSparseEncoder(movie_f.movieID)\n",
    "    )\n",
    "movie_encoder.add_column(\n",
    "        'movie_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(movie_f.movie_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def augment_user_id(user_ids):\n",
    "    return user_encoder.encode_df(\n",
    "        user_f.reindex(user_ids).reset_index()\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    return movie_encoder.encode_df(\n",
    "        movie_f.reindex(movie_ids).reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Train/Test Blocks\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks),(df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7e813",
   "metadata": {},
   "source": [
    "## Evaluation and Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc61da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.78 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:05<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9744198592190163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.81 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [02:03<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738884136608861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.85 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [03:04<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738137269951479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.12 w0 = 3.88 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [04:09<00:00,  1.61it/s]\n",
      "alpha = 1.12 w0 = 3.90 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [04:42<00:00,  1.77it/s]\n",
      "alpha = 1.14 w0 = 3.75 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:11<00:00,  1.39it/s]\n",
      "alpha = 1.13 w0 = 3.78 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:57<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733395483947272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.81 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [03:05<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9731564794960696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.85 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [03:44<00:00,  1.78it/s]\n",
      "alpha = 1.13 w0 = 3.86 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [04:40<00:00,  1.79it/s]\n",
      "alpha = 1.15 w0 = 3.77 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:07<00:00,  1.49it/s]\n",
      "alpha = 1.15 w0 = 3.82 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [02:16<00:00,  1.46it/s]\n",
      "alpha = 1.15 w0 = 3.83 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [03:13<00:00,  1.55it/s]\n",
      "alpha = 1.15 w0 = 3.89 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [04:11<00:00,  1.59it/s]\n",
      "alpha = 1.15 w0 = 3.91 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [05:36<00:00,  1.49it/s]\n",
      "alpha = 1.16 w0 = 3.79 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:34<00:00,  1.05it/s]\n",
      "alpha = 1.17 w0 = 3.84 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [03:23<00:00,  1.02s/it]\n",
      "alpha = 1.16 w0 = 3.87 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [05:34<00:00,  1.11s/it]\n",
      "alpha = 1.16 w0 = 3.91 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [07:52<00:00,  1.18s/it]\n",
      "alpha = 1.16 w0 = 3.93 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [08:18<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Return root mean square error metric\n",
    "def RMSE(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    return np.sqrt(np.average((x - y) ** 2))\n",
    "\n",
    "# Function to do parameter tuning\n",
    "def validation(user_encoder,movie_encoder,df_train,train_blocks,test_blocks,val_predictions):\n",
    "    group_shapes = user_encoder.encoder_shapes + movie_encoder.encoder_shapes\n",
    "\n",
    "    rank = [8,10,12,14]\n",
    "    n_iter = [100,200,300,400,500]\n",
    "    n_samples = [95,195,295,395,495]\n",
    "\n",
    "    best_rmse = 1\n",
    "    best_r = 0\n",
    "    best_n = 0\n",
    "    best_s = 0\n",
    "\n",
    "    for r in rank:\n",
    "        for i in range(len(n_iter)):\n",
    "            fm = myfm.MyFMRegressor(rank=r,random_seed=1234)\n",
    "            fm.fit(None, df_train.rating.values, X_rel=train_blocks, \n",
    "                   group_shapes=group_shapes,n_iter=n_iter[i], n_kept_samples=n_samples[i])\n",
    "            test_predictions = fm.predict(None, test_blocks)\n",
    "            rmse = RMSE(val_predictions,test_predictions)\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_r = r\n",
    "                best_n = n_iter[i]\n",
    "                best_s = n_samples[i]\n",
    "                print(best_rmse)\n",
    "                \n",
    "    return best_rmse,best_r,best_n,best_s\n",
    "\n",
    "best_rmse,best_r,best_n,best_s = validation(user_encoder,movie_encoder,df_train,train_blocks,test_blocks,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50af65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE using model is 0.9731564794960696\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation RMSE using model is \" + str(best_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac285dc6",
   "metadata": {},
   "source": [
    "# Generate Features & Train the model on Total Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb901a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 1.13 w0 = 3.78 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [03:02<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<myfm.gibbs.MyFMGibbsRegressor at 0x1595de400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get & Store Implicit Features on total data\n",
    "user_f = pd.DataFrame(np.arange(10000),columns=['userID'])\n",
    "user_f['implicit_features'] = df_total.groupby('userID').movieID.agg(string_agg).reindex(user_f.index).fillna('')\n",
    "user_f['rating_features'] = df_total.groupby('userID').rating.agg(aggr).reindex(user_f.index).fillna('')\n",
    "user_f['user_metadata'] = user_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "movie_f = pd.DataFrame(np.arange(1000),columns=['movieID'])\n",
    "movie_f['implicit_features'] = df_total.groupby('movieID').userID.agg(string_agg).reindex(movie_f.index).fillna('')\n",
    "movie_f['rating_features'] = df_total.groupby('movieID').rating.agg(aggr).reindex(movie_f.index).fillna('')\n",
    "movie_f['movie_metadata'] = movie_f[['implicit_features', 'rating_features']].to_dict(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "#Create User Encoder for total data\n",
    "user_encoder = DataFrameEncoder().add_column(\n",
    "    'userID', CategoryValueToSparseEncoder(user_f.userID)\n",
    "    )\n",
    "\n",
    "user_encoder.add_column(\n",
    "        'user_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(user_f.user_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "#Create Movie Encoder\n",
    "movie_encoder = DataFrameEncoder().add_column(\n",
    "    'movieID', CategoryValueToSparseEncoder(movie_f.movieID)\n",
    "    )\n",
    "movie_encoder.add_column(\n",
    "        'movie_metadata',\n",
    "        WeightMultipleValuesToSparseEncoder(movie_f.movie_metadata, normalize=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def augment_user_id(user_ids):\n",
    "    return user_encoder.encode_df(\n",
    "        user_f.reindex(user_ids).reset_index()\n",
    "    )\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    return movie_encoder.encode_df(\n",
    "        movie_f.reindex(movie_ids).reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "#Generate Train Blocks on total data\n",
    "group_shapes = user_encoder.encoder_shapes + movie_encoder.encoder_shapes\n",
    "\n",
    "total_train_blocks = []\n",
    "for source, target in [(df_total, total_train_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )\n",
    "\n",
    "\n",
    "#Train the model\n",
    "fm = myfm.MyFMRegressor(rank=best_r,random_seed=1234)\n",
    "fm.fit(None, df_total.rating.values, X_rel=total_train_blocks,\n",
    "    group_shapes=group_shapes,\n",
    "    n_iter=best_n, n_kept_samples=best_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68a8d2",
   "metadata": {},
   "source": [
    "## Generate predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8db3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Submission File\n",
    "sub_pd = pd.read_csv('../data/sampleSubmission.csv')\n",
    "sub_users, sub_movies, sub_pred = extract_users_items_predictions(sub_pd)\n",
    "sub_test_ratings_dict = {'userID': sub_users,'movieID': sub_movies,'rating': sub_pred}\n",
    "sub_df = pd.DataFrame(sub_test_ratings_dict)\n",
    "\n",
    "#Generate Submission Test Blocks\n",
    "sub_test_blocks = []\n",
    "for source, target in [(sub_df, sub_test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.userID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movieID, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )\n",
    "\n",
    "#Generate Predictions and create submission csv    \n",
    "predictions = fm.predict(None, sub_test_blocks)\n",
    "sub_pd['Prediction'] = predictions\n",
    "sub_pd.set_index(\"Id\", inplace = True)\n",
    "sub_pd.to_csv(\"submission_weighted_bayesian_svdpp_flipped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cf8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
